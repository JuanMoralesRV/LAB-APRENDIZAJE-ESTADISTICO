{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70086771-ad90-497d-9b51-22626c9cce63",
   "metadata": {},
   "source": [
    "# Laboratorio de regresión - 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f666e0e-9e63-49f4-96e1-053c5b1738c3",
   "metadata": {},
   "source": [
    "|                |   |\r\n",
    ":----------------|---|\r\n",
    "| **Nombre**     |Juan Alvaro Morales Ramirez Valadez   |\r\n",
    "| **Fecha**     18/09/2025 |   |\r\n",
    "| **Expediente*745903* |   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f352dc-5863-4685-af3c-25f8fcf60841",
   "metadata": {},
   "source": [
    "## Validación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73fccec-9651-4f74-9d56-a3c2b2097e19",
   "metadata": {},
   "source": [
    "### Hemos estado usando `train_test_split` en nuestros modelos anteriores.\n",
    "\n",
    "### ¿Por qué?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fe97ab-a033-4d0f-ab73-0cdabe591655",
   "metadata": {},
   "source": [
    "Para hacer un train_test_split, es decir, para dividir el dataset en una parte para entrenar el modelo y otra para evaluarlo, con el objetivo de que el modelo pueda aprender realmente a partir de una porción de los datos y validar su desempeño en datos que no ha visto antes. Esto evita que el modelo se machetee (overfitting), es decir, que solo funcione bien con los datos de entrenamiento pero no generalice correctamente a datos nuevos o futuros, mejorando así su capacidad para hacer predicciones o estimaciones confiables en escenarios reales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a60a028-ed60-4a5c-9308-dee4862e2bac",
   "metadata": {},
   "source": [
    "### Si la muestra es un subset de la población y queremos generalizar sobre la población, ¿no sería mejor utilizar todos los datos al entrenar un modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50989a32-59e7-4bef-9b60-89f543d8ca81",
   "metadata": {},
   "source": [
    "No, porque si usamos todos los datos para entrenar, el modelo no estaría aprendiendo realmente, sino más bien memorizando esos datos específicos. Esto puede generar un R2 muy acertado con ese conjunto de entrenamiento, pero cuando le presentemos datos nuevos, que no ha visto antes, el modelo no generalizará bien y tendrá un rendimiento pobre. Por eso es fundamental reservar una parte de los datos para validación o prueba, para evaluar si el modelo puede predecir correctamente fuera de la muestra que usó para entrenar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8b1ad0-3c68-4f6a-b16b-c0b1353d7dd2",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98d96f3-7370-4161-aa67-75f10e5817cd",
   "metadata": {},
   "source": [
    "El propósito de volver a muestrear dentro de nuestro dataset es tener una idea de qué tan buena podría ser la generalización de nuestro modelo. Imagina un dataset ya separado en dos mitades. Utilizas la primera mitad para entrenar el modelo y pruebas en la segunda mitad; la segunda mitad eran datos invisibles para el modelo al momento de entrenar. Esto nos lleva a tres escenario típicos:\n",
    "\n",
    "1. Si el modelo hace buenas predicciones en la segunda mitad, significa que la primera mitad era \"suficiente\" para generalizar.\n",
    "2. Si el modelo no hace buenas predicciones en la segunda mitad, pero sí en la primera mitad, podría ser que había información importante en la segunda mitad que debió haber sido tomada en cuenta al entrenar, o un problema de overfitting.\n",
    "3. Si el modelo no hace buenas predicciones en la segunda mitad, y tampoco en la primera mitad, se tendrían que revisar los factores y/o el modelo seleccionado.\n",
    "\n",
    "El caso ideal sería el 1, pero por estadística los errores y varianzas tienen como entrada el número de muestas, por lo que tenemos menos seguridad de nuestros resutados al usar menos muestras. Si vemos que el modelo generaliza bien podemos unir de nuevo el dataset y entrenar sobre el dataset completo.\n",
    "\n",
    "En el caso 2 está el problema de que no podemos saber qué información es necesaria para el entrenamiento apropiado del modelo; esto nos lleva a pensar que debemos usar el dataset completo para entrenar, pero esto nos lleva al mismo problema de no saber si el modelo puede generalizar.\n",
    "\n",
    "El problema sólo incrementa si se tienen hiperparámetros en el modelo (e.g. $\\lambda$ en regularización)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16176ad-41fc-4f3c-b865-2eb4219152e2",
   "metadata": {},
   "source": [
    "## Leave-One-Out Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f7165d-5b5d-4e92-ae7f-7edb12eea745",
   "metadata": {},
   "source": [
    "Este método de validación es una colección de $n$ `train-test-split`. Teniendo un dataset de $n$ muestras, la lógica es:\n",
    "1. Saca una muestra del dataset.\n",
    "2. Entrena tu modelo con las $n-1$ muestras.\n",
    "3. Evalúa tu modelo en la muestra que quedó fuera con el métrico que más se ajuste a la aplicación.\n",
    "4. Regresa la muestra al dataset.\n",
    "5. Repite 1-4 con muestras diferentes hasta haber hecho el procedimiento $n$ veces para $n$ muestras.\n",
    "6. Calcula la media y desviación estándar de los métricos guardados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21340b80-8fa4-4cdf-8fe4-85e4a35febcd",
   "metadata": {},
   "source": [
    "Con los resultados del proceso de validación podemos saber qué tan bueno podría ser el modelo seleccionado con los datos (con/sin transformaciones)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0983bf1c-a6a2-42e4-a522-92bba6b450ab",
   "metadata": {},
   "source": [
    "### Ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e5f076-bc52-482c-9560-ecd0c125efa7",
   "metadata": {},
   "source": [
    "Utiliza el dataset `Motor Trend Car Road Tests`. Elimina la columna `model` y entrena 32 modelos diferentes utilizando Leave-One-Out Cross Validation con target `mpg`. Utiliza MSE como métrico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89510da9-15a9-41e5-bd0e-855291acec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7199ca1-32f0-463b-925f-76613d608a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.182\n",
      "17.067\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('Motor Trend Car Road Tests.xlsx')\n",
    "df = df.drop(columns ='model', axis = 1)\n",
    "\n",
    "x = df.drop(columns='mpg')\n",
    "y = df['mpg']\n",
    "\n",
    "mse=[]\n",
    "\n",
    "for i in range(len(df)):\n",
    "    #1-Sacar una muestra del dataset\n",
    "    x_train = x.drop(i)\n",
    "    y_train = y.drop(i)\n",
    "\n",
    "    x_test = x.iloc[[i]]\n",
    "    y_test = y.iloc[i]\n",
    "   \n",
    "    #2-Entrena tu modelo con las n-1 muestras\n",
    "    modelo = LinearRegression()\n",
    "    modelo.fit(x_train, y_train)\n",
    "\n",
    "    #3- Evalúa tu modelo en la muestra que quedó fuera con el métrico que más se ajuste a la aplicación.\n",
    "    y_pred = modelo.predict(x_test)\n",
    "    mse_i = mean_squared_error([y_test], [y_pred])\n",
    "   \n",
    "    #4- Regresa la muestra al dataset.\n",
    "    mse.append(mse_i)\n",
    "   \n",
    "    #5 -Repite 1-4 con muestras diferentes hasta haber hecho el procedimiento veces para muestras.\n",
    "    #6- Calcula la media y desviación estándar de los métricos guardados.\n",
    "    mse_mean = np.mean(mse)\n",
    "   \n",
    "    mse_std = np.std(mse)\n",
    "\n",
    "print(round(mse_mean,3))\n",
    "print(round(mse_std,3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8724bdb-e50b-4470-b53a-2d9843fae6ea",
   "metadata": {},
   "source": [
    "### Interpreta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19904df-1fe6-433a-b1bd-a7ce86ce0eef",
   "metadata": {},
   "source": [
    "El MSE mean indica en promedio que tanto se alejan las predicciones del modelo sobre los datos reales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8ee166-b442-49f8-bf40-db9aaf9c3db8",
   "metadata": {},
   "source": [
    "El STD mean indcia cuanto vario mi error a lo largo de cada muestra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541e2903-2874-48f1-be68-3848d30fa43c",
   "metadata": {},
   "source": [
    "En este caso la variabilidad es mas grande que mi error medio, lo que indica un bajo desmepeño del modelo, osea gran variabilidad en los errores de mis muestras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc61dd1-fa5f-43b0-969a-592f8e9fc56f",
   "metadata": {},
   "source": [
    "## K-Folds Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbca526-2c69-4c70-b6b4-270fc51d825b",
   "metadata": {},
   "source": [
    "El dataset `Motor Trend Car Road Tests` sólo tiene 32 muestras, y utilizar un modelo sencillo de regresión múltiple hace que usar LOOCV sea muy rápido. El dataset `California Housing` tiene $20640$ muestras para $9$ columnas, entonces realizar un ajuste sobre una transformación o sobre el modelo y luego calcular el impacto esperado podría tomar más tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a437812-c00e-400f-ae7d-110b3afa5dc3",
   "metadata": {},
   "source": [
    "La solución propuesta es dividir el dataset en *k* folds (partes iguales), ajustar en *k-1* folds y probar en el restante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb82cc3-0d35-442a-a12b-f9c6fd131af2",
   "metadata": {},
   "source": [
    "### Ejercicio 2\n",
    "Utiliza el dataset `California Housing` y haz K-folds Cross Validation con 10 folds. Utiliza el MSE como métrico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba50e361-edcd-4cdb-9609-68f20d6fca97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (20640, 8) (20640,)\n",
      "Dataset Features: ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
      "Dataset Target: ['MedHouseVal']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "df = fetch_california_housing()\n",
    "print(\"Dataset Shape:\", housing.data.shape, housing.target.shape)\n",
    "print(\"Dataset Features:\", housing.feature_names)\n",
    "print(\"Dataset Target:\", housing.target_names)\n",
    "X = df.data\n",
    "y = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4e8570a4-76bb-4d81-a90b-43647b0df438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.527\n",
      "0.035\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Mezclar las filas aleatoriamente\n",
    "X, y = shuffle(X, y)\n",
    "\n",
    "# Definir el número de folds\n",
    "k = 10\n",
    "n_samples = X.shape[0]\n",
    "fold_size = n_samples // k\n",
    "\n",
    "mse_scores = []\n",
    "\n",
    "# k-fold manual\n",
    "for i in range(k):\n",
    "    #Definir el tamaño de cada fold\n",
    "    start = i * fold_size\n",
    "    end = (i + 1) * fold_size if i != k - 1 else n_samples \n",
    "\n",
    "    # Seleccionar el test\n",
    "    X_test = X[start:end]\n",
    "    y_test = y[start:end]\n",
    "\n",
    "    # Unir el resto de fold para hacer el entrenamiento\n",
    "    X_train = np.concatenate((X[:start], X[end:]), axis=0)\n",
    "    y_train = np.concatenate((y[:start], y[end:]), axis=0)\n",
    "\n",
    "    # Modelo\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluar modelo\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_scores.append(mse)\n",
    "\n",
    "# Resultados\n",
    "mse_mean = np.mean(mse_scores)\n",
    "mse_std = np.std(mse_scores)\n",
    "\n",
    "print(round(mse_mean,3))\n",
    "print(round(mse_std,3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f7098f-a1de-4508-b3ff-af1484561856",
   "metadata": {},
   "source": [
    "### Interpreta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fbaf4d-f62b-46d9-9a35-23fcdd50a8ca",
   "metadata": {},
   "source": [
    "El MSE promedio de 0.527 indica que el modelo tiene un buen desempeño, con predicciones cercanas a los valores reales en promedio, mientras que la baja desviación estándar de 0.035 muestra que este desempeño es consistente y estable a lo largo de las diferentes particiones del dataset, lo que sugiere que el modelo generaliza bien y no presenta grandes variaciones en su error entre los distintos folds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5792ac-6d38-4f02-bf10-aeaa0a040d17",
   "metadata": {},
   "source": [
    "## Referencia\n",
    "\n",
    "James, G., Witten, D., Hastie, T., Tibshirani, R.,, Taylor, J. (2023). An Introduction to Statistical Learning with Applications in Python. Cham: Springer. ISBN: 978-3-031-38746-3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
